{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4840be8-90ac-4550-ac96-454e23804803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.8.1+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.1%2Bcu111-cp39-cp39-win_amd64.whl (3055.6 MB)\n",
      "Collecting torchvision==0.9.1+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.1%2Bcu111-cp39-cp39-win_amd64.whl (1.9 MB)\n",
      "Collecting torchaudio===0.8.1\n",
      "  Downloading torchaudio-0.8.1-cp39-none-win_amd64.whl (109 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.22.3-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "Collecting typing-extensions\n",
      "  Using cached typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
      "Collecting pillow>=4.1.1\n",
      "  Downloading Pillow-9.1.0-cp39-cp39-win_amd64.whl (3.3 MB)\n",
      "Installing collected packages: typing-extensions, numpy, torch, pillow, torchvision, torchaudio\n",
      "Successfully installed numpy-1.22.3 pillow-9.1.0 torch-1.8.1+cu111 torchaudio-0.8.1 torchvision-0.9.1+cu111 typing-extensions-4.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "923df554-c395-4e17-aafc-e6f857167865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
      "Collecting packaging>=20.0\n",
      "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\zenop\\miniconda3\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\zenop\\miniconda3\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
      "Collecting tokenizers!=0.11.3,>=0.11.1\n",
      "  Downloading tokenizers-0.11.6-cp39-cp39-win_amd64.whl (3.2 MB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.3.15-cp39-cp39-win_amd64.whl (274 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp39-cp39-win_amd64.whl (151 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.6.0-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\zenop\\miniconda3\\lib\\site-packages (from transformers) (1.22.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\zenop\\miniconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Collecting pyparsing!=3.0.5,>=2.0.2\n",
      "  Using cached pyparsing-3.0.7-py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\zenop\\miniconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\zenop\\miniconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\zenop\\miniconda3\\lib\\site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\zenop\\miniconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\zenop\\miniconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Collecting click\n",
      "  Using cached click-8.1.2-py3-none-any.whl (96 kB)\n",
      "Requirement already satisfied: six in c:\\users\\zenop\\miniconda3\\lib\\site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Installing collected packages: pyparsing, regex, pyyaml, packaging, joblib, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed click-8.1.2 filelock-3.6.0 huggingface-hub-0.4.0 joblib-1.1.0 packaging-21.3 pyparsing-3.0.7 pyyaml-6.0 regex-2022.3.15 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ced184a4-d1b4-476a-8d60-17b6dce421e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2523d175-cbae-4157-bcee-1f29eb886e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.32k/1.32k [00:00<00:00, 1.36MB/s]\n",
      "Downloading: 100%|██████████| 4.95G/4.95G [12:08<00:00, 7.30MB/s]\n",
      "Downloading: 100%|██████████| 200/200 [00:00<00:00, 202kB/s]\n",
      "Downloading: 100%|██████████| 779k/779k [00:00<00:00, 1.34MB/s]\n",
      "Downloading: 100%|██████████| 446k/446k [00:00<00:00, 770kB/s] \n",
      "Downloading: 100%|██████████| 90.0/90.0 [00:00<00:00, 171kB/s]\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model='EleutherAI/gpt-neo-1.3B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a230f8a1-f412-4713-b934-e0126af5afc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"School is\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f78c298d-5290-4d3d-9d3f-b3dcd48ccf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "res = generator(prompt, max_length=50, do_sample=True, temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6565a2c1-5364-4e0c-9d39-a850ad66d21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "School is an important social institution that helps students succeed in a globalized world. But to succeed in a globalized world there should be no borders, no schools to shut down. And the most important lesson in the story of how to succeed in a\n"
     ]
    }
   ],
   "source": [
    "print(res[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2566a3-22e9-4f28-97d6-f57afc74dca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
